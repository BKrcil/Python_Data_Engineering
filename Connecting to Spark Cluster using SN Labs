Datasets
In this lab you will be using dataset(s):

Modified version of car mileage dataset. Original dataset available at https://archive.ics.uci.edu/ml/datasets/auto+mpg
Modified version of diamonds dataset. Original dataset available at https://www.openml.org/search?type=data&sort=runs&id=42225&status=active
Setup
For this lab, we will be using the following libraries:

PySpark for connecting to the Spark Cluster
Installing Required Libraries
Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to connect to this cluster.

If you download this notebook and run on your laptop, you will NOT be able to connect the spark cluster running on the SN labs.

The following required libraries are not pre-installed in the Skills Network Labs environment. You will need to run the following cell to install them:

!pip install pyspark==3.1.2 -q
!pip install findspark -q
Importing Required Libraries
We recommend you import all required libraries in one place (here):

# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')
​
# FindSpark simplifies the process of using Apache Spark with Python
​
import findspark
findspark.init()
​
# import SparkSession
from pyspark.sql import SparkSession
Examples
Task 1 - Create a spark session
SparkSession.builder.appName("Getting Started with Spark").getOrCreate()
#Create SparkSession
#Here 'Getting Started with Spark' is the application name
#Ignore any warnings by SparkSession command
​
spark = SparkSession.builder.appName("Getting Started with Spark").getOrCreate()
Task 2 - Download the data file
!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv
​


Task 3 - Load the data in a csv file into a dataframe
# using the spark.read.csv function we load the data into a dataframe.
# the header = True mentions that there is a header row in out csv file
# the inferSchema = True, tells spark to automatically find out the data types of the columns.
​
# Load mpg dataset
mpg_data = spark.read.csv("mpg.csv", header=True, inferSchema=True)
​
Task 4 - Explore the data set
Let's print the schema of the dataset

mpg_data.printSchema()
root
 |-- MPG: double (nullable = true)
 |-- Cylinders: integer (nullable = true)
 |-- Engine Disp: double (nullable = true)
 |-- Horsepower: integer (nullable = true)
 |-- Weight: integer (nullable = true)
 |-- Accelerate: double (nullable = true)
 |-- Year: integer (nullable = true)
 |-- Origin: string (nullable = true)

Let's look at some sample rows from the dataset we loaded:

# show top 5 rows from the dataset
mpg_data.head(5)
[Row(MPG=15.0, Cylinders=8, Engine Disp=390.0, Horsepower=190, Weight=3850, Accelerate=8.5, Year=70, Origin='American'),
 Row(MPG=21.0, Cylinders=6, Engine Disp=199.0, Horsepower=90, Weight=2648, Accelerate=15.0, Year=70, Origin='American'),
 Row(MPG=18.0, Cylinders=6, Engine Disp=199.0, Horsepower=97, Weight=2774, Accelerate=15.5, Year=70, Origin='American'),
 Row(MPG=16.0, Cylinders=8, Engine Disp=304.0, Horsepower=150, Weight=3433, Accelerate=12.0, Year=70, Origin='American'),
 Row(MPG=14.0, Cylinders=8, Engine Disp=455.0, Horsepower=225, Weight=3086, Accelerate=10.0, Year=70, Origin='American')]
Task 5 - Stop the spark session
First we identify the target. Target is the value that our machine learning model needs to predict

spark.stop()
Exercises
Exercise 1 - Create a Spark Session
Create a spark session with appname "Diamond data analysis"

spark = SparkSession.builder.appName("Getting Started with Spark").getOrCreate()
​

spark = SparkSession.builder.appName("Diamond data analysis").getOrCreate()
Exercise 2 - Load the dataset into a dataframe
Download the data set from "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv"

!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv
​  


Load diamond dataset into a dataframe named diamond_data


diamond_data = spark.read.csv("diamonds.csv", header=True, inferSchema=True)
​
                                                                                

Exercise 3 - Explore the data
Print the schema of the dataframe

#your code goes here
diamond_data.printSchema()
root
 |-- s: integer (nullable = true)
 |-- carat: double (nullable = true)
 |-- cut: string (nullable = true)
 |-- color: string (nullable = true)
 |-- clarity: string (nullable = true)
 |-- depth: double (nullable = true)
 |-- table: double (nullable = true)
 |-- price: integer (nullable = true)
 |-- x: double (nullable = true)
 |-- y: double (nullable = true)
 |-- z: double (nullable = true)


diamond_data.printSchema()

Exercise 4 - Print the top 5 rows of the dataframe
#your code goes here
diamond_data.head(5)
[Row(s=1, carat=0.23, cut='Ideal', color='E', clarity='SI2', depth=61.5, table=55.0, price=326, x=3.95, y=3.98, z=2.43),
 Row(s=2, carat=0.21, cut='Premium', color='E', clarity='SI1', depth=59.8, table=61.0, price=326, x=3.89, y=3.84, z=2.31),
 Row(s=3, carat=0.23, cut='Good', color='E', clarity='VS1', depth=56.9, table=65.0, price=327, x=4.05, y=4.07, z=2.31),
 Row(s=4, carat=0.29, cut='Premium', color='I', clarity='VS2', depth=62.4, table=58.0, price=334, x=4.2, y=4.23, z=2.63),
 Row(s=5, carat=0.31, cut='Good', color='J', clarity='SI2', depth=63.3, table=58.0, price=335, x=4.34, y=4.35, z=2.75)]

Exercise 5 - Stop the spark session

spark.stop()

Replace the code in Task 1 - "Create a spark session" with the one given below. Make sure you use your spark-master and port details.

spark = SparkSession.builder.appName("YourAppName").master("spark://spark-master:port").getOrCreate()
