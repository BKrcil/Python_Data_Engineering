Objectives¶
After completing this lab you will be able to:

Use Pandas to load data sets.
Identify the target and features.
Use Logistic Regression to build a classifier.
Use metrics to evaluate the model.
Make predictions using a trained model.
Datasets
In this lab you will be using dataset(s):

Pima Indians Diabetes Database. Available at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database
Setup
For this lab, we will be using the following libraries:

pandas for managing the data.
sklearn for machine learning and machine-learning-pipeline related functions.
Installing Required Libraries
The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the # sign before !pip in the code cell below.

# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.
# !pip install pandas==1.3.4
# !pip install scikit-learn==0.20.1
​
The following required libraries are not pre-installed in the Skills Network Labs environment. You will need to run the following cell to install them:

Importing Required Libraries
We recommend you import all required libraries in one place (here):

# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')
​
import pandas as pd
from sklearn.linear_model import LogisticRegression
​
#import functions for train test split
​
from sklearn.model_selection import train_test_split
​
​
# functions for metrics
​
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
Task 1 - Load the data in a csv file into a dataframe
# the data set is available at the url below.
URL = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diabetes.csv"
​
# using the read_csv function in the pandas library, we load the data into a dataframe.
​
df = pd.read_csv(URL)
Let's look at some sample rows from the dataset we loaded:

# show 5 random rows from the dataset
df.sample(5)
Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age	Outcome
198	4	109	64	44	99	34.8	0.905	26	1
747	1	81	74	41	57	46.3	1.096	32	0
150	1	136	74	50	204	37.4	0.399	24	0
78	0	131	0	0	0	43.2	0.270	26	1
701	6	125	78	31	0	27.6	0.565	49	1
Let's find out the number of rows and columns in the dataset:

df.shape
(768, 9)
Let's plot the types and count of Outcome

df.Outcome.value_counts()
0    500
1    268
Name: Outcome, dtype: int64
df.Outcome.value_counts().plot.bar()
<AxesSubplot:>

There are 500 people without diabetes and 268 people with diabetes in this dataset.

Task 2 - Identify the target column and the data columns
First we identify the target. Target is the value that our machine learning model needs to classify

y = df["Outcome"]
We identify the features next. Features are the input values our machine learning model learns from

X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']]
Task 3 - Split the data set
We split the data set in the ratio of 70:30. 70% training data, 30% testing data.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)
Task 4 - Build and train a classifier
Create a Logistic Regression model

classifier = LogisticRegression()
Train/Fit the model on training data

classifier.fit(X_train,y_train)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
Task 5 - Evaluate the model
Your model is now trained. Time to evaluate the model.

#Higher the score, better the model.
classifier.score(X_test,y_test)
0.7402597402597403
To compute the detailed metrics we need two values, the original mileage and the predicted mileage.

original_values = y_test
predicted_values = classifier.predict(X_test)
Precision
precision_score(original_values, predicted_values) # Higher the value the better the model
0.7543859649122807
Recall
recall_score(original_values, predicted_values) # Higher the value the better the model
0.48314606741573035
F1 Score
f1_score(original_values, predicted_values) # Higher the value the better the model
0.589041095890411
Confusion Matrix
confusion_matrix(original_values, predicted_values) # can be used to manually calculate various met
array([[128,  14],
       [ 46,  43]])
Exercises
URL2 = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diabetes.csv"
​
Exercise 1 - Load a dataset
Load the cancer dataset available at URL2


df2 = pd.read_csv(URL2)

Exercise 2 - Identify the target column and the data columns
use the Outcome column as target
use columns 'Pregnancies', 'Glucose', 'Insulin', 'DiabetesPedigreeFunction', 'Age' as features

y = df2["Outcome"]
X = df2[['Pregnancies', 'Glucose', 'Insulin', 'DiabetesPedigreeFunction', 'Age']]

Exercise 3 - Split the data
Split the dataset into training and testing sets. Make 33% of the data as testing set. Use 40 as random state

X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=40)

Exercise 4 - Build and Train a new classifier
Create a new Classifier and train using the training data


classifier2 = LogisticRegression()
classifier2.fit(X_train,y_train)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)

Exercise 5 - Evaluate the model
original_values = y_test
predicted_values = classifier2.predict(X_test)
Print the metrics :

Precision Score
Recall Score
F1 Score






#your code goes here
print(precision_score(original_values, predicted_values))
print(recall_score(original_values, predicted_values))
print(f1_score(original_values, predicted_values))
0.7678571428571429
0.43434343434343436
0.5548387096774193
